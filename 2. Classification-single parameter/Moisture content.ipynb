{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a9d302-020d-48a3-8af4-da9b808e12e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from scipy.io import loadmat\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# ===================== paths (relative) =====================\n",
    "\n",
    "ROOT = Path(__file__).resolve().parent\n",
    "DATA_DIR = ROOT / \"data\"\n",
    "EXCEL_PATH = DATA_DIR / \"pea_cluster.xlsx\"\n",
    "MAT_DIR = DATA_DIR / \"mat\"\n",
    "SHEET_NAME_EXPLICIT = None\n",
    "\n",
    "\n",
    "# ===================== helpers =====================\n",
    "def pick_moisture_sheet(excel_path: Path, explicit: str | None = None) -> str:\n",
    "    if explicit:\n",
    "        return explicit\n",
    "    xls = pd.ExcelFile(excel_path)\n",
    "    keys = [\"moisture\", \"moist\", \"water content\"]\n",
    "    for s in xls.sheet_names:\n",
    "        low = str(s).strip().lower()\n",
    "        if any(k in low for k in keys):\n",
    "            return s\n",
    "    raise ValueError(\"No moisture-related sheet name found. Set SHEET_NAME_EXPLICIT explicitly.\")\n",
    "\n",
    "\n",
    "def build_labels_from_sheet(excel_path: Path, sheet_name: str):\n",
    "    df = pd.read_excel(excel_path, sheet_name=sheet_name)\n",
    "    class_cols = [c for c in df.columns[4:] if not df[c].isna().all()]\n",
    "\n",
    "    sample_to_class = {}\n",
    "    for idx, col in enumerate(class_cols, start=1):\n",
    "        ids = pd.to_numeric(df[col], errors=\"coerce\").dropna().astype(int).tolist()\n",
    "        for sid in ids:\n",
    "            sample_to_class[int(sid)] = idx\n",
    "\n",
    "    sample_ids = sorted(sample_to_class.keys())\n",
    "    labels_num = [sample_to_class[sid] for sid in sample_ids]\n",
    "    return sample_ids, labels_num, [str(c) for c in class_cols]\n",
    "\n",
    "\n",
    "def load_sample_mean_spectrum(mat_dir: Path, sid: int, use_mask: bool = True) -> np.ndarray:\n",
    "    samp_path = mat_dir / f\"prep_sample{sid}.mat\"\n",
    "    if not samp_path.exists():\n",
    "        raise FileNotFoundError(f\"Missing file: {samp_path}\")\n",
    "\n",
    "    d = loadmat(samp_path)\n",
    "    varname = f\"prep_sample{sid}\"\n",
    "    if varname not in d:\n",
    "        candidates = [k for k in d.keys() if not k.startswith(\"__\")]\n",
    "        if len(candidates) == 1:\n",
    "            varname = candidates[0]\n",
    "        else:\n",
    "            raise KeyError(f\"Variable '{varname}' not found in {samp_path.name}. Candidates: {candidates}\")\n",
    "    arr = np.asarray(d[varname])\n",
    "\n",
    "    if arr.ndim == 3:\n",
    "        H, W, B = arr.shape\n",
    "        pixxbands = arr.reshape(-1, B)\n",
    "\n",
    "        if use_mask:\n",
    "            mpath = mat_dir / f\"prep_mask{sid}.mat\"\n",
    "            if mpath.exists():\n",
    "                dm = loadmat(mpath)\n",
    "                mvar = f\"prep_mask{sid}\"\n",
    "                if mvar not in dm:\n",
    "                    cm = [k for k in dm.keys() if not k.startswith(\"__\")]\n",
    "                    mvar = cm[0]\n",
    "                m = np.asarray(dm[mvar]).reshape(-1).astype(bool)\n",
    "                if m.size == pixxbands.shape[0]:\n",
    "                    pixxbands = pixxbands[m]\n",
    "\n",
    "    elif arr.ndim == 2:\n",
    "        n0, n1 = arr.shape\n",
    "        pixxbands = arr.T if n0 < n1 else arr\n",
    "\n",
    "        if use_mask:\n",
    "            mpath = mat_dir / f\"prep_mask{sid}.mat\"\n",
    "            if mpath.exists():\n",
    "                dm = loadmat(mpath)\n",
    "                mvar = f\"prep_mask{sid}\"\n",
    "                if mvar not in dm:\n",
    "                    cm = [k for k in dm.keys() if not k.startswith(\"__\")]\n",
    "                    mvar = cm[0]\n",
    "                m = np.asarray(dm[mvar]).reshape(-1).astype(bool)\n",
    "                if m.size == pixxbands.shape[0]:\n",
    "                    pixxbands = pixxbands[m]\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported array shape for sample {sid}: {arr.shape}\")\n",
    "\n",
    "    pixxbands = pixxbands[~np.isnan(pixxbands).any(axis=1)]\n",
    "    if pixxbands.size == 0:\n",
    "        raise ValueError(f\"Empty valid pixels for sample {sid}. Check data/mask.\")\n",
    "\n",
    "    return pixxbands.mean(axis=0)\n",
    "\n",
    "\n",
    "def ensure_min_splits(y: np.ndarray, max_splits: int = 5) -> int:\n",
    "    cnt = Counter(y)\n",
    "    min_count = min(cnt.values())\n",
    "    n_splits = min(max_splits, min_count)\n",
    "    if n_splits < 2:\n",
    "        raise ValueError(f\"Too few samples in the smallest class ({min_count}) for StratifiedKFold.\")\n",
    "    return n_splits\n",
    "\n",
    "\n",
    "# ===================== main =====================\n",
    "if __name__ == \"__main__\":\n",
    "    if not EXCEL_PATH.exists():\n",
    "        raise FileNotFoundError(f\"Excel not found: {EXCEL_PATH}\")\n",
    "    if not MAT_DIR.exists():\n",
    "        raise FileNotFoundError(f\"MAT directory not found: {MAT_DIR}\")\n",
    "\n",
    "    sheet = pick_moisture_sheet(EXCEL_PATH, explicit=SHEET_NAME_EXPLICIT)\n",
    "    print(f\"[INFO] Sheet: {sheet}\")\n",
    "\n",
    "    sample_ids, labels_num, class_cols = build_labels_from_sheet(EXCEL_PATH, sheet)\n",
    "\n",
    "    X_list, y_list, kept_ids = [], [], []\n",
    "    for sid, lab_num in zip(sample_ids, labels_num):\n",
    "        try:\n",
    "            spec = load_sample_mean_spectrum(MAT_DIR, int(sid), use_mask=True)\n",
    "            X_list.append(spec)\n",
    "            y_list.append(int(lab_num))\n",
    "            kept_ids.append(int(sid))\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Skip sample {sid}: {e}\")\n",
    "\n",
    "    if len(X_list) == 0:\n",
    "        raise RuntimeError(\"No valid samples were loaded. Check MAT files and masks.\")\n",
    "\n",
    "    X = np.vstack(X_list).astype(np.float32)\n",
    "    y_raw = np.asarray(y_list, dtype=int)\n",
    "    kept_ids = np.asarray(kept_ids, dtype=int)\n",
    "    print(f\"[INFO] Samples: {len(y_raw)} | X shape: {X.shape}\")\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y_raw)\n",
    "\n",
    "    class_names = []\n",
    "    for k in range(len(le.classes_)):\n",
    "        original_num = le.classes_[k]\n",
    "        class_names.append(str(class_cols[original_num - 1]))\n",
    "\n",
    "    n_splits = ensure_min_splits(y, max_splits=5)\n",
    "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    clf = Pipeline([\n",
    "        (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
    "        (\"pca\", PCA(n_components=0.99, random_state=42)),\n",
    "        (\"xgb\", XGBClassifier(\n",
    "            n_estimators=400,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.05,\n",
    "            subsample=0.85,\n",
    "            colsample_bytree=0.85,\n",
    "            reg_lambda=1.0,\n",
    "            reg_alpha=0.0,\n",
    "            objective=\"multi:softprob\",\n",
    "            eval_metric=\"mlogloss\",\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "        )),\n",
    "    ])\n",
    "\n",
    "    scores = cross_val_score(clf, X, y, cv=cv, scoring=\"accuracy\")\n",
    "    print(f\"[CV] n_splits: {n_splits}\")\n",
    "    print(f\"[CV] fold accuracy: {np.round(scores, 4)}\")\n",
    "    print(f\"[CV] mean ± std: {scores.mean():.4f} ± {scores.std():.4f}\")\n",
    "\n",
    "    y_pred_cv = cross_val_predict(clf, X, y, cv=cv, method=\"predict\")\n",
    "\n",
    "    labels_sorted = sorted(np.unique(y))\n",
    "    target_names = [class_names[i] for i in labels_sorted]\n",
    "\n",
    "    cm_cv = confusion_matrix(y, y_pred_cv, labels=labels_sorted)\n",
    "    print(\"\\n[CV] Confusion matrix:\\n\", cm_cv)\n",
    "    print(\"\\n[CV] Report:\\n\", classification_report(y, y_pred_cv, target_names=target_names, digits=4))\n",
    "\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm_cv, display_labels=target_names)\n",
    "    disp.plot(values_format=\"d\", xticks_rotation=45)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    OUT_DIR = ROOT / \"outputs\" / \"moisture\"\n",
    "    OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    plt.savefig(OUT_DIR / \"confusion_matrix.png\", dpi=220)\n",
    "    plt.show()\n",
    "\n",
    "    pd.DataFrame({\n",
    "        \"sample_id\": kept_ids,\n",
    "        \"true_idx\": y,\n",
    "        \"cv_pred_idx\": y_pred_cv,\n",
    "        \"true_label\": [target_names[labels_sorted.index(i)] for i in y],\n",
    "        \"cv_pred_label\": [target_names[labels_sorted.index(i)] for i in y_pred_cv],\n",
    "    }).to_csv(OUT_DIR / \"moisture_cv_predictions.csv\", index=False)\n",
    "\n",
    "    pd.DataFrame({\"cv_fold_acc\": scores}).to_csv(OUT_DIR / \"moisture_cv_scores.csv\", index=False)\n",
    "\n",
    "    pd.DataFrame(\n",
    "        cm_cv,\n",
    "        index=[f\"True_{n}\" for n in target_names],\n",
    "        columns=[f\"Pred_{n}\" for n in target_names],\n",
    "    ).to_csv(OUT_DIR / \"moisture_cv_confusion_matrix.csv\", index=True)\n",
    "\n",
    "    print(f\"\\n[SAVE] {OUT_DIR}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
