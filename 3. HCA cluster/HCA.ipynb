{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f520cf4-2a13-4583-b580-554500ac46ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Patch-level training with sample-level soft voting (3 classes)\n",
    "\n",
    "- Input:\n",
    "  Patch CSV with columns:\n",
    "    ['patch_id', 'sample_id', <spectral features ...>]\n",
    "\n",
    "  Excel file with class columns:\n",
    "    I / II / III -> sample_id lists\n",
    "\n",
    "- Preprocessing:\n",
    "  SNV (+ optional Savitzky-Golay first derivative)\n",
    "  StandardScaler -> PCA\n",
    "\n",
    "- Models:\n",
    "  Logistic Regression (ElasticNet)\n",
    "  Random Forest\n",
    "  Extra Trees\n",
    "  XGBoost\n",
    "  Optional LightGBM\n",
    "  Soft Voting Ensemble\n",
    "\n",
    "- Evaluation:\n",
    "  GroupKFold (by sample_id, no leakage)\n",
    "\n",
    "- Output:\n",
    "  Patch-level and sample-level Accuracy / Macro-F1\n",
    "  Confusion matrices and CSV reports\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.signal import savgol_filter\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Optional LightGBM\n",
    "try:\n",
    "    from lightgbm import LGBMClassifier\n",
    "    HAS_LGBM = True\n",
    "except Exception:\n",
    "    HAS_LGBM = False\n",
    "\n",
    "\n",
    "# ===================== Paths (relative) =====================\n",
    "BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "\n",
    "PATCH_CSV = os.path.join(BASE_DIR, \"data\", \"pea_patch_dataset.csv\")\n",
    "EXCEL_3CLS = os.path.join(BASE_DIR, \"data\", \"pea_cluster.xlsx\")\n",
    "OUT_DIR = os.path.join(BASE_DIR, \"results_patch_sample_voting\")\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "# ===================== Global parameters =====================\n",
    "RANDOM_STATE = 42\n",
    "PCA_DIM = 60\n",
    "USE_SG = True\n",
    "SG_WINDOW = 21\n",
    "SG_POLY = 3\n",
    "SG_DERIV = 1\n",
    "N_SPLITS = 5\n",
    "\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "\n",
    "# ===================== Utilities =====================\n",
    "def snv(X):\n",
    "    mu = X.mean(axis=1, keepdims=True)\n",
    "    sd = X.std(axis=1, keepdims=True) + 1e-12\n",
    "    return (X - mu) / sd\n",
    "\n",
    "\n",
    "def sg_derivative(X, window=21, poly=3, deriv=1):\n",
    "    if window % 2 == 0:\n",
    "        window += 1\n",
    "    window = min(window, X.shape[1] - (1 - X.shape[1] % 2))\n",
    "    if window < 5:\n",
    "        window = 5\n",
    "\n",
    "    out = np.empty_like(X)\n",
    "    for i in range(X.shape[0]):\n",
    "        out[i] = savgol_filter(\n",
    "            X[i],\n",
    "            window_length=window,\n",
    "            polyorder=poly,\n",
    "            deriv=deriv\n",
    "        )\n",
    "    return out\n",
    "\n",
    "\n",
    "def load_labels_from_excel(excel_path):\n",
    "    df = pd.read_excel(excel_path, engine=\"openpyxl\")\n",
    "    df.columns = [str(c).strip().upper() for c in df.columns]\n",
    "\n",
    "    cols = [c for c in [\"I\", \"II\", \"III\"] if any(col.startswith(c) for col in df.columns)]\n",
    "    assert len(cols) == 3, \"Expected 3 class columns (I / II / III)\"\n",
    "\n",
    "    id_to_label = {}\n",
    "    for lab, cname in enumerate(cols, start=1):\n",
    "        col = next(c for c in df.columns if c.startswith(cname))\n",
    "        ids = pd.to_numeric(df[col], errors=\"coerce\").dropna().astype(int).tolist()\n",
    "        for sid in ids:\n",
    "            id_to_label[sid] = lab\n",
    "\n",
    "    return id_to_label\n",
    "\n",
    "\n",
    "def aggregate_sample_probs(df_probs):\n",
    "    true_by_sample = (\n",
    "        df_probs.groupby(\"sample_id\")[\"y_true\"]\n",
    "        .agg(lambda x: np.bincount(x).argmax())\n",
    "    )\n",
    "\n",
    "    prob_cols = [c for c in df_probs.columns if c.startswith(\"p\")]\n",
    "    mean_probs = df_probs.groupby(\"sample_id\")[prob_cols].mean()\n",
    "    pred_by_sample = mean_probs.values.argmax(axis=1)\n",
    "\n",
    "    return true_by_sample.values, pred_by_sample\n",
    "\n",
    "\n",
    "# ===================== Load data =====================\n",
    "print(\"[INFO] Loading patch-level CSV...\")\n",
    "df = pd.read_csv(PATCH_CSV)\n",
    "\n",
    "non_spec = [\"patch_id\", \"sample_id\"]\n",
    "spec_cols = [c for c in df.columns if c not in non_spec]\n",
    "df[spec_cols] = df[spec_cols].astype(float)\n",
    "\n",
    "print(f\"[INFO] Patches: {len(df)}, Bands: {len(spec_cols)}, Samples: {df['sample_id'].nunique()}\")\n",
    "\n",
    "label_map = load_labels_from_excel(EXCEL_3CLS)\n",
    "\n",
    "df = df[df[\"sample_id\"].astype(int).isin(label_map.keys())].copy()\n",
    "df[\"y\"] = df[\"sample_id\"].astype(int).map(label_map)\n",
    "\n",
    "X_raw = df[spec_cols].values\n",
    "y_raw = df[\"y\"].values\n",
    "groups = df[\"sample_id\"].values\n",
    "\n",
    "print(f\"[INFO] After filtering: patches={len(df)}, class distribution={np.bincount(y_raw)[1:]}\")\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y_raw)\n",
    "\n",
    "\n",
    "# ===================== Preprocessing =====================\n",
    "print(\"[INFO] Preprocessing...\")\n",
    "X = snv(X_raw)\n",
    "\n",
    "if USE_SG:\n",
    "    X = sg_derivative(X, SG_WINDOW, SG_POLY, SG_DERIV)\n",
    "\n",
    "X_std = StandardScaler().fit_transform(X)\n",
    "\n",
    "pca = PCA(n_components=min(PCA_DIM, X_std.shape[1]), random_state=RANDOM_STATE)\n",
    "X_pca = pca.fit_transform(X_std)\n",
    "\n",
    "print(f\"[INFO] PCA shape: {X_pca.shape}\")\n",
    "\n",
    "\n",
    "# ===================== Models =====================\n",
    "estimators = []\n",
    "\n",
    "estimators.append((\n",
    "    \"logreg\",\n",
    "    LogisticRegression(\n",
    "        max_iter=5000,\n",
    "        solver=\"saga\",\n",
    "        penalty=\"elasticnet\",\n",
    "        l1_ratio=0.5,\n",
    "        C=2.0,\n",
    "        class_weight=\"balanced\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "))\n",
    "\n",
    "estimators.append((\n",
    "    \"rf\",\n",
    "    RandomForestClassifier(\n",
    "        n_estimators=800,\n",
    "        class_weight=\"balanced_subsample\",\n",
    "        n_jobs=-1,\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "))\n",
    "\n",
    "estimators.append((\n",
    "    \"et\",\n",
    "    ExtraTreesClassifier(\n",
    "        n_estimators=1000,\n",
    "        class_weight=\"balanced_subsample\",\n",
    "        n_jobs=-1,\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "))\n",
    "\n",
    "estimators.append((\n",
    "    \"xgb\",\n",
    "    XGBClassifier(\n",
    "        n_estimators=800,\n",
    "        max_depth=8,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.85,\n",
    "        colsample_bytree=0.85,\n",
    "        objective=\"multi:softprob\",\n",
    "        eval_metric=\"mlogloss\",\n",
    "        n_jobs=-1,\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "))\n",
    "\n",
    "if HAS_LGBM:\n",
    "    estimators.append((\n",
    "        \"lgbm\",\n",
    "        LGBMClassifier(\n",
    "            objective=\"multiclass\",\n",
    "            n_estimators=1000,\n",
    "            learning_rate=0.05,\n",
    "            class_weight=\"balanced\",\n",
    "            random_state=RANDOM_STATE\n",
    "        )\n",
    "    ))\n",
    "\n",
    "voter = VotingClassifier(\n",
    "    estimators=estimators,\n",
    "    voting=\"soft\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "models = estimators + [(\"voting_soft\", voter)]\n",
    "\n",
    "\n",
    "# ===================== GroupKFold evaluation =====================\n",
    "gkf = GroupKFold(n_splits=N_SPLITS)\n",
    "\n",
    "summary = []\n",
    "best_name = None\n",
    "best_scores = (-1, -1)\n",
    "best_true = None\n",
    "best_pred = None\n",
    "\n",
    "for name, clf in models:\n",
    "    print(f\"\\n[MODEL] {name}\")\n",
    "    patch_true, patch_pred = [], []\n",
    "    sample_true, sample_pred = [], []\n",
    "\n",
    "    for fold, (tr, te) in enumerate(gkf.split(X_pca, y_enc, groups), 1):\n",
    "        clf.fit(X_pca[tr], y_enc[tr])\n",
    "\n",
    "        proba = clf.predict_proba(X_pca[te])\n",
    "        yhat = proba.argmax(axis=1)\n",
    "\n",
    "        patch_true.append(y_enc[te])\n",
    "        patch_pred.append(yhat)\n",
    "\n",
    "        df_fold = pd.DataFrame(\n",
    "            proba, columns=[f\"p{i}\" for i in range(proba.shape[1])]\n",
    "        )\n",
    "        df_fold[\"sample_id\"] = groups[te]\n",
    "        df_fold[\"y_true\"] = y_enc[te]\n",
    "\n",
    "        yt_s, yp_s = aggregate_sample_probs(df_fold)\n",
    "        sample_true.append(yt_s)\n",
    "        sample_pred.append(yp_s)\n",
    "\n",
    "        acc = accuracy_score(yt_s, yp_s)\n",
    "        f1m = f1_score(yt_s, yp_s, average=\"macro\")\n",
    "        print(f\"  Fold {fold}: sample-ACC={acc:.4f}, Macro-F1={f1m:.4f}\")\n",
    "\n",
    "    ypt = np.concatenate(patch_true)\n",
    "    ypp = np.concatenate(patch_pred)\n",
    "    acc_p = accuracy_score(ypt, ypp)\n",
    "    f1_p = f1_score(ypt, ypp, average=\"macro\")\n",
    "\n",
    "    yst = np.concatenate(sample_true)\n",
    "    ysp = np.concatenate(sample_pred)\n",
    "    acc_s = accuracy_score(yst, ysp)\n",
    "    f1_s = f1_score(yst, ysp, average=\"macro\")\n",
    "\n",
    "    summary.append({\n",
    "        \"model\": name,\n",
    "        \"patch_acc\": acc_p,\n",
    "        \"patch_macro_f1\": f1_p,\n",
    "        \"sample_acc\": acc_s,\n",
    "        \"sample_macro_f1\": f1_s\n",
    "    })\n",
    "\n",
    "    if (f1_s, acc_s) > best_scores:\n",
    "        best_scores = (f1_s, acc_s)\n",
    "        best_name = name\n",
    "        best_true = yst\n",
    "        best_pred = ysp\n",
    "\n",
    "\n",
    "# ===================== Save results =====================\n",
    "summary_df = pd.DataFrame(summary).sort_values(\n",
    "    [\"sample_macro_f1\", \"sample_acc\"], ascending=False\n",
    ")\n",
    "summary_df.to_csv(\n",
    "    os.path.join(OUT_DIR, \"model_comparison.csv\"),\n",
    "    index=False\n",
    ")\n",
    "\n",
    "y_true_lab = le.inverse_transform(best_true)\n",
    "y_pred_lab = le.inverse_transform(best_pred)\n",
    "\n",
    "report_df = pd.DataFrame(\n",
    "    classification_report(y_true_lab, y_pred_lab, digits=4, output_dict=True)\n",
    ").T\n",
    "\n",
    "cm = confusion_matrix(y_true_lab, y_pred_lab, labels=le.classes_)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm,\n",
    "    index=[f\"True_{c}\" for c in le.classes_],\n",
    "    columns=[f\"Pred_{c}\" for c in le.classes_]\n",
    ")\n",
    "\n",
    "report_df.to_csv(os.path.join(OUT_DIR, f\"{best_name}_classification_report.csv\"))\n",
    "cm_df.to_csv(os.path.join(OUT_DIR, f\"{best_name}_confusion_matrix.csv\"))\n",
    "\n",
    "print(f\"\\n[BEST MODEL] {best_name}\")\n",
    "print(f\"Sample ACC={best_scores[1]:.4f}, Macro-F1={best_scores[0]:.4f}\")\n",
    "print(f\"Results saved to: {OUT_DIR}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
